# Introduction to Statistical Learning

> Exercise solutions for "Introduction to Statistical Learning with Applications
> in R, 2nd edition", written in R using [org mode](https://orgmode.org).

## Solutions
### [Chapter 5](05-resampling_methods.org)
- [x] Lab
  - [x] The validation set approach
  - [x] Leave-one-out cross-validation
  - [x] k-fold cross-validation
  - [x] The bootstrap
- [ ] Exercises
  - [ ] Exercise 1
  - [x] Exercise 2
  - [x] Exercise 3
  - [x] Exercise 4
  - [x] Exercise 5
  - [x] Exercise 6
  - [ ] Exercise 7
  - [ ] Exercise 8
  - [ ] Exercise 9
### [Chapter 6](06-regularization_methods.org)
- [x] Lab
  - [x] Subset selection methods
  - [x] Ridge regression and the lasso
  - [x] PCR and PLS regression
- [ ] Exercises
  - [x] Exercise 1
  - [x] Exercise 2
  - [x] Exercise 3
  - [x] Exercise 4
  - [ ] Exercise 5
  - [ ] Exercise 6
  - [ ] Exercise 7
  - [ ] Exercise 8
  - [ ] Exercise 9
  - [x] Exercise 10
  - [ ] Exercise 11
### [Chapter 7](07-moving_beyond_linearity.org)
- [x] Lab
  - [x] Polynomial regression and step functions
  - [x] Splines
  - [x] GAMs
- [ ] Exercises
  - [ ] Exercise 1
  - [ ] Exercise 2
  - [ ] Exercise 3
  - [ ] Exercise 4
  - [ ] Exercise 5
  - [ ] Exercise 6
  - [ ] Exercise 7
  - [ ] Exercise 8
  - [ ] Exercise 9
  - [ ] Exercise 10
  - [ ] Exercise 11
  - [ ] Exercise 12
### [Chapter 8](08-tree_based_methods.org)
- [ ] Lab
  - [x] Fitting classification trees
  - [x] Fitting regression trees
  - [ ] Bagging and random forests
  - [ ] Boosting
  - [ ] Bayesian additive regression trees
- [ ] Exercises
  - [ ] Exercise 1
  - [ ] Exercise 2
  - [ ] Exercise 3
  - [ ] Exercise 4
  - [ ] Exercise 5
  - [ ] Exercise 6
  - [ ] Exercise 7
  - [ ] Exercise 8
  - [ ] Exercise 9
  - [ ] Exercise 10
  - [ ] Exercise 11
  - [ ] Exercise 12
