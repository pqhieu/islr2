#+startup: showall inlineimages
#+property: header-args:R :session *R* :family "Concourse 3"

#+begin_src R :results silent
library(ISLR2)
library(leaps)  # For best subset selection
library(glmnet)  # For ridge regression and the lasso
library(pls)   # For principal components regression
#+end_src

* Lab
** Subset Selection Methods
*** Best Subset Selection
Here we apply the best subset selection approach to the =Hitters= data. We notice
that the =Salary= variable is missing for some of the players. We can use the
=is.na()= and =na.omit()= functions to identify and remove rows that have missing
values.

#+begin_src R :results output :exports both
dim(Hitters)
sum(is.na(Hitters$Salary))
Hitters <- na.omit(Hitters)
dim(Hitters)
#+end_src

#+RESULTS:
: [1] 322  20
: [1] 59
: [1] 263  20

The =regsubsets()= function performs best subset selection, where best is
quantified using RSS.

#+begin_src R :results output :exports both
regfit.full <- regsubsets(Salary ~ ., data = Hitters, nvmax = 19)
reg.summary <- summary(regfit.full)
reg.summary
#+end_src

#+RESULTS:
#+begin_example
Subset selection object
Call: regsubsets.formula(Salary ~ ., data = Hitters, nvmax = 19)
19 Variables  (and intercept)
           Forced in Forced out
AtBat          FALSE      FALSE
Hits           FALSE      FALSE
HmRun          FALSE      FALSE
Runs           FALSE      FALSE
RBI            FALSE      FALSE
Walks          FALSE      FALSE
Years          FALSE      FALSE
CAtBat         FALSE      FALSE
CHits          FALSE      FALSE
CHmRun         FALSE      FALSE
CRuns          FALSE      FALSE
CRBI           FALSE      FALSE
CWalks         FALSE      FALSE
LeagueN        FALSE      FALSE
DivisionW      FALSE      FALSE
PutOuts        FALSE      FALSE
Assists        FALSE      FALSE
Errors         FALSE      FALSE
NewLeagueN     FALSE      FALSE
1 subsets of each size up to 19
Selection Algorithm: exhaustive
          AtBat Hits HmRun Runs RBI Walks Years CAtBat CHits CHmRun CRuns CRBI
1  ( 1 )  " "   " "  " "   " "  " " " "   " "   " "    " "   " "    " "   "*"
2  ( 1 )  " "   "*"  " "   " "  " " " "   " "   " "    " "   " "    " "   "*"
3  ( 1 )  " "   "*"  " "   " "  " " " "   " "   " "    " "   " "    " "   "*"
4  ( 1 )  " "   "*"  " "   " "  " " " "   " "   " "    " "   " "    " "   "*"
5  ( 1 )  "*"   "*"  " "   " "  " " " "   " "   " "    " "   " "    " "   "*"
6  ( 1 )  "*"   "*"  " "   " "  " " "*"   " "   " "    " "   " "    " "   "*"
7  ( 1 )  " "   "*"  " "   " "  " " "*"   " "   "*"    "*"   "*"    " "   " "
8  ( 1 )  "*"   "*"  " "   " "  " " "*"   " "   " "    " "   "*"    "*"   " "
9  ( 1 )  "*"   "*"  " "   " "  " " "*"   " "   "*"    " "   " "    "*"   "*"
10  ( 1 ) "*"   "*"  " "   " "  " " "*"   " "   "*"    " "   " "    "*"   "*"
11  ( 1 ) "*"   "*"  " "   " "  " " "*"   " "   "*"    " "   " "    "*"   "*"
12  ( 1 ) "*"   "*"  " "   "*"  " " "*"   " "   "*"    " "   " "    "*"   "*"
13  ( 1 ) "*"   "*"  " "   "*"  " " "*"   " "   "*"    " "   " "    "*"   "*"
14  ( 1 ) "*"   "*"  "*"   "*"  " " "*"   " "   "*"    " "   " "    "*"   "*"
15  ( 1 ) "*"   "*"  "*"   "*"  " " "*"   " "   "*"    "*"   " "    "*"   "*"
16  ( 1 ) "*"   "*"  "*"   "*"  "*" "*"   " "   "*"    "*"   " "    "*"   "*"
17  ( 1 ) "*"   "*"  "*"   "*"  "*" "*"   " "   "*"    "*"   " "    "*"   "*"
18  ( 1 ) "*"   "*"  "*"   "*"  "*" "*"   "*"   "*"    "*"   " "    "*"   "*"
19  ( 1 ) "*"   "*"  "*"   "*"  "*" "*"   "*"   "*"    "*"   "*"    "*"   "*"
          CWalks LeagueN DivisionW PutOuts Assists Errors NewLeagueN
1  ( 1 )  " "    " "     " "       " "     " "     " "    " "
2  ( 1 )  " "    " "     " "       " "     " "     " "    " "
3  ( 1 )  " "    " "     " "       "*"     " "     " "    " "
4  ( 1 )  " "    " "     "*"       "*"     " "     " "    " "
5  ( 1 )  " "    " "     "*"       "*"     " "     " "    " "
6  ( 1 )  " "    " "     "*"       "*"     " "     " "    " "
7  ( 1 )  " "    " "     "*"       "*"     " "     " "    " "
8  ( 1 )  "*"    " "     "*"       "*"     " "     " "    " "
9  ( 1 )  "*"    " "     "*"       "*"     " "     " "    " "
10  ( 1 ) "*"    " "     "*"       "*"     "*"     " "    " "
11  ( 1 ) "*"    "*"     "*"       "*"     "*"     " "    " "
12  ( 1 ) "*"    "*"     "*"       "*"     "*"     " "    " "
13  ( 1 ) "*"    "*"     "*"       "*"     "*"     "*"    " "
14  ( 1 ) "*"    "*"     "*"       "*"     "*"     "*"    " "
15  ( 1 ) "*"    "*"     "*"       "*"     "*"     "*"    " "
16  ( 1 ) "*"    "*"     "*"       "*"     "*"     "*"    " "
17  ( 1 ) "*"    "*"     "*"       "*"     "*"     "*"    "*"
18  ( 1 ) "*"    "*"     "*"       "*"     "*"     "*"    "*"
19  ( 1 ) "*"    "*"     "*"       "*"     "*"     "*"    "*"
#+end_example

An asterisk indicates that a given variable is included in the model. By
default, =regsubsets()= only reports results up to the best eight-variable
model. But the =nvmax= option can be used in order to return as many variable as
desired.

Plotting RSS, adjusted $R^2$, $C_p$, and BIC for all of the models will help us
decide which model to select. The =regsubsets()= function has a built-in =plot()=
command which can be used to display the selected variables for the best model
with a given number of predictors.

#+begin_src R :results output file graphics :file assets/ch06/subset.svg :exports both :width 4 :height 4
plot(regfit.full, scale = "adjr2")
#+end_src

#+RESULTS:
[[file:assets/ch06/subset.svg]]
** Ridge Regression and the Lasso
We will now perform ridge regression and the lasso in order to predict =Salary= on
the =Hitters= data.

#+begin_src R :results silent
x <- model.matrix(Salary ~ ., Hitters)[, -1]
y <- Hitters$Salary
#+end_src

*** Ridge Regression
The =glmnet()= function has an =alpha= argument that determines what type of model
is fit. If =alpha=0= then a ridge regression model is fit, and if =alpha=1= then a
lasso model is fit.

By default the =glmnet()= function performs ridge regression for an automatically
selected range of $\lambda$ values. Associated with each value of $\lambda$ is a vector of
ridge regression coefficients.

#+begin_src R :results output :exports both
grid <- 10^seq(10, -2, length = 100)
ridge.mod <- glmnet(x, y, alpha = 0, lambda = grid)
dim(coef(ridge.mod))
#+end_src

#+RESULTS:
: [1]  20 100

We now split the samples into a training set and a test set in order to estimate
the test error. In general, it would be better to use cross-validation to choose
the tuning paramter $\lambda$.

#+begin_src R :results output file graphics :file assets/ch06/ridge.svg :exports both :width 4 :height 4
set.seed(1)
train <- sample(1:nrow(x), nrow(x) / 2)
test <- (-train)
y.test <- y[test]

set.seed(1)
cv.out <- cv.glmnet(x[train,], y[train], alpha = 0)
plot(cv.out)
#+end_src

#+RESULTS:
[[file:assets/ch06/ridge.svg]]

Finally, we refit our ridge regression model on the full dataset, using the $\lambda$
value chose by cross-validation, and examine the coefficient estimates.

#+begin_src R :results output :exports both
bestlam <- cv.out$lambda.min
out <- glmnet(x, y, alpha = 0)
predict(out, type = "coefficients", s = bestlam)[1:20, ]
#+end_src

#+RESULTS:
:  (Intercept)        AtBat         Hits        HmRun         Runs          RBI
:  15.44383120   0.07715547   0.85911582   0.60103106   1.06369007   0.87936105
:        Walks        Years       CAtBat        CHits       CHmRun        CRuns
:   1.62444617   1.35254778   0.01134999   0.05746654   0.40680157   0.11456224
:         CRBI       CWalks      LeagueN    DivisionW      PutOuts      Assists
:   0.12116504   0.05299202  22.09143197 -79.04032656   0.16619903   0.02941950
:       Errors   NewLeagueN
:  -1.36092945   9.12487765

As expected, none of the coefficients are zero --- ridge regression does not
perform variable selection.

*** The Lasso
We now ask whether the lasso can yield either a more accurate or a more
interpretable model than ridge regression.

#+begin_src R :results output file graphics :file assets/ch06/lasso.svg :exports both :width 4 :height 4
lasso.mod <- glmnet(x[train, ], y[train], alpha = 1, lambda = grid)
plot(lasso.mod)
#+end_src

#+RESULTS:
[[file:assets/ch06/lasso.svg]]

The lasso has a substaintial advantage over ridge regression in that the
resulting coefficient estimates are sparse.

#+begin_src R :results output :exports both
set.seed(1)
cv.out <- cv.glmnet(x[train,], y[train], alpha = 1)
bestlam <- cv.out$lambda.min
out <- glmnet(x, y, alpha = 1, lambda = grid)
predict(out, type = "coefficients", s = bestlam)[1:20, ]
#+end_src

#+RESULTS:
:   (Intercept)         AtBat          Hits         HmRun          Runs
:    1.27479059   -0.05497143    2.18034583    0.00000000    0.00000000
:           RBI         Walks         Years        CAtBat         CHits
:    0.00000000    2.29192406   -0.33806109    0.00000000    0.00000000
:        CHmRun         CRuns          CRBI        CWalks       LeagueN
:    0.02825013    0.21628385    0.41712537    0.00000000   20.28615023
:     DivisionW       PutOuts       Assists        Errors    NewLeagueN
: -116.16755870    0.23752385    0.00000000   -0.85629148    0.00000000
** PCR and PLS Regression
*** Principal Components Regression
Principal components regression (PCR) can be performed using the =pcr()= function,
which is part of the =pls= library.

#+begin_src R :results output :exports both
set.seed(2)
pcr.fit <- pcr(Salary ~ ., data = Hitters, scale = TRUE, validation = "CV")
summary(pcr.fit)
#+end_src

#+RESULTS:
#+begin_example
Data: 	X dimension: 263 19
	Y dimension: 263 1
Fit method: svdpc
Number of components considered: 19

VALIDATION: RMSEP
Cross-validated using 10 random segments.
       (Intercept)  1 comps  2 comps  3 comps  4 comps  5 comps  6 comps
CV             452    351.9    353.2    355.0    352.8    348.4    343.6
adjCV          452    351.6    352.7    354.4    352.1    347.6    342.7
       7 comps  8 comps  9 comps  10 comps  11 comps  12 comps  13 comps
CV       345.5    347.7    349.6     351.4     352.1     353.5     358.2
adjCV    344.7    346.7    348.5     350.1     350.7     352.0     356.5
       14 comps  15 comps  16 comps  17 comps  18 comps  19 comps
CV        349.7     349.4     339.9     341.6     339.2     339.6
adjCV     348.0     347.7     338.2     339.7     337.2     337.6

TRAINING: % variance explained
        1 comps  2 comps  3 comps  4 comps  5 comps  6 comps  7 comps  8 comps
X         38.31    60.16    70.84    79.03    84.29    88.63    92.26    94.96
Salary    40.63    41.58    42.17    43.22    44.90    46.48    46.69    46.75
        9 comps  10 comps  11 comps  12 comps  13 comps  14 comps  15 comps
X         96.28     97.26     97.98     98.65     99.15     99.47     99.75
Salary    46.86     47.76     47.82     47.85     48.10     50.40     50.55
        16 comps  17 comps  18 comps  19 comps
X          99.89     99.97     99.99    100.00
Salary     53.01     53.85     54.61     54.61
#+end_example

The CV score is provided for each possible number of components, ranging from
$M=0$ onwards. One can also plot the cross-validation scores using the
=validationplot()= function.

#+begin_src R :results output file graphics :file assets/ch06/pcr.svg :exports both :width 4 :height 4
validationplot(pcr.fit, val.type = "MSEP")
#+end_src

#+RESULTS:
[[file:assets/ch06/pcr.svg]]

We now perform PCR on the training data and evaluate its test set performance.

#+begin_src R :results output :exports both
set.seed(1)
pcr.fit <- pcr(Salary ~ ., data = Hitters, subset = train, scale = TRUE, validation = "CV")
pcr.pred <- predict(pcr.fit, x[test, ], ncomp = 5)
mean((pcr.pred - y.test)^2)
#+end_src

#+RESULTS:
: [1] 142811.8

This test set MSE is competitive with the results obtained using ridge
regression and the lasso. However, the final model is difficult to interpret
because it does not perform any kind of variable selection or even directly
produce coefficient estimates.
*** Partial Least Squares
We implement partial least squares using the =plsr()= function.

#+begin_src R :results output :exports both
set.seed(1)
pls.fit <- plsr(Salary ~ ., data = Hitters, subset = train, scale = TRUE, validation = "CV")
summary(pls.fit)
#+end_src

#+RESULTS:
#+begin_example
Data: 	X dimension: 131 19
	Y dimension: 131 1
Fit method: kernelpls
Number of components considered: 19

VALIDATION: RMSEP
Cross-validated using 10 random segments.
       (Intercept)  1 comps  2 comps  3 comps  4 comps  5 comps  6 comps
CV           428.3    325.5    329.9    328.8    339.0    338.9    340.1
adjCV        428.3    325.0    328.2    327.2    336.6    336.1    336.6
       7 comps  8 comps  9 comps  10 comps  11 comps  12 comps  13 comps
CV       339.0    347.1    346.4     343.4     341.5     345.4     356.4
adjCV    336.2    343.4    342.8     340.2     338.3     341.8     351.1
       14 comps  15 comps  16 comps  17 comps  18 comps  19 comps
CV        348.4     349.1     350.0     344.2     344.5     345.0
adjCV     344.2     345.0     345.9     340.4     340.6     341.1

TRAINING: % variance explained
        1 comps  2 comps  3 comps  4 comps  5 comps  6 comps  7 comps  8 comps
X         39.13    48.80    60.09    75.07    78.58    81.12    88.21    90.71
Salary    46.36    50.72    52.23    53.03    54.07    54.77    55.05    55.66
        9 comps  10 comps  11 comps  12 comps  13 comps  14 comps  15 comps
X         93.17     96.05     97.08     97.61     97.97     98.70     99.12
Salary    55.95     56.12     56.47     56.68     57.37     57.76     58.08
        16 comps  17 comps  18 comps  19 comps
X          99.61     99.70     99.95    100.00
Salary     58.17     58.49     58.56     58.62
#+end_example

The lowest cross-validation error occurs when only $M=1$ partial least squares
directions are used. We now evaluate the corresponding test set MSE.

#+begin_src R :results output :exports both
pls.pred <- predict(pls.fit, x[test, ], ncomp = 1)
mean((pls.pred - y.test)^2)
#+end_src

#+RESULTS:
: [1] 151995.3

The test MSE is slightly higher than ridge regression, the lasso, and PCR.
